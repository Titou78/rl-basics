# RL-Gym

[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)

# STATUS : WORK IN PROGRESS

The goal of this repo is to implement any RL algorithms and try to benchmarks them with the [Gym](https://github.com/openai/gym) framework made by OpenAI.  
Made in Python with [Pytorch](https://github.com/pytorch/pytorch).

**Policy based:**

- [x] REINFORCE [[1]](#references)
- [x] A2C [[2]](#references)
- [x] PPO [[3]](#references)
- [ ] DDPG [[4]](#references)
- [ ] TD3 [[5]](#references)
- [ ] SAC [[6]](#references)
---

## Setup

Clone the code repo and install the requirements.

```
git clone https://github.com/valentin-cnt/rl-gym.git
cd rl-gym
pip install -r requirements.txt
```

---

## Run

```

```

---

## Results

---

## References

- [1] [Policy Gradient Methods for Reinforcement Learning with FunctionApproximation](https://proceedings.neurips.cc/paper/1999/file/464d828b85b0bed98e80ade0a5c43b0f-Paper.pdf)
- [2] [Asynchronous Methods for Deep Reinforcement Learning](https://arxiv.org/abs/1602.01783)
- [3] [Proximal Policy Optimization Algorithms](https://arxiv.org/abs/1707.06347)
- [4] [Deterministic Policy Gradient Algorithms](https://proceedings.mlr.press/v32/silver14.pdf)
- [5] [Addressing Function Approximation Error in Actor-Critic Methods](https://arxiv.org/abs/1802.09477)
- [6] [Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor](https://arxiv.org/abs/1801.01290)
